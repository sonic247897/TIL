library("stringr")
library("stringr")
#패턴
mytext <- "test$uuuuu"
mytext2 <- "https://cran.r-project.org/"
#패턴을 실행해주는 함수
str_extract(mytext, ".+(:)")
#패턴을 실행해주는 함수
str_extract(mytext2, ".+(:)")
# : 앞에 문자가 여러개 와도 됨
str_extract(mytext2, ".+(?=:)")
str_extract(mytext2, ".+(?<=:)")
# .+의 뜻은 : 앞에 문자가 여러개 와도 된다는 뜻
# 패턴과 일치하는 문자를 찾아 일치 문자 바로 전까지 리턴
str_extract(mytext2, ".+(?=:)") # ?:(자바에서도 사용 가능)
str_extract(mytext, ".+(?=$)")
str_extract(mytext, ".+(?=\\$)") #
str_extract(mytext, "(?<=\\$).*") # $를 인식시키려면 \\붙여줘야 함
#### 후방탐색 ####
# 패턴과 일치하는 문자를 찾아 일치 문자 뒤부터 리턴
str_extract(mytext, "(?<=\\$).*") # $를 인식시키려면 \\붙여줘야 함
paste(str, collapse = " ") #어떤 기호를 이용해서 연결할 건지
#문자열 관련 함수
# paste - 벡터를 연결해서 하나의 문자열로 생성
# paste0 - 여러 개를 연결
str <- c("java", "hadoop", "R", "mongodb")
paste(str, collapse = " ") #어떤 기호를 이용해서 연결할 건지
paste(str, collapse = ",")
paste0(text1, text2)
paste0(mytext, mytext2)
gsub("u", "", mytext) # 문자 치환
#패턴
mytext <- "     test$uuuuu"
gsub("u", "", mytext) # 문자 치환
data <- gsub("u", "", mytext) # 문자 치환
data
data <- gsub("u", "U", mytext) # 문자 치환
data
length(data)
str_trim(data)
install.packages("mongolite")
library("mongolite")
library("stringr")
url <- "https://www.clien.net/service/group/community?&od=T31&po=0"
url_data <- readLines(url) # url접속도 대신해줌
url_data <- readLines(url, encoding = "UTF-8") # url접속도 대신해줌(사이트에서 정보 받아옴)
# 인코딩 확인!!
url_data
class(url_data)
#class(url_data) #character
length(url_data)
# 정보확인=============================
#class(url_data) #character
#length(url_data)
head(url_data)
tail(url_data)
# 정보확인=============================
#class(url_data) #character
#length(url_data)
#head(url_data)
#tail(url_data)
# =====================================
url_data[200]
# 조건에 만족하는 데이터를 필터링
# 문자열에 패턴을 적용해서 일치여부를 T/F로 리턴
# str_detect(패턴을 검사할 문자열, 패턴)
str_detect(url_data, "subject_fixed")
# 조건에 만족하는 데이터를 필터링
# 문자열에 패턴을 적용해서 일치여부를 T/F로 리턴
# str_detect(패턴을 검사할 문자열, 패턴)
url_data[str_detect(url_data, "subject_fixed")] #TRUE와 FALSE로 나타나는 결과값을 배열에 넣으면 TRUE인 원소만 출력된다
#### 데이터 필터링: title ####
# 1. str_detect(패턴을 검사할 문자열, 패턴)를 이용해서 웹페이지 전체에서 필요한 데이터만 먼저 추출 -> TRUE와 FALSE를 리턴
filter_data <- url_data[str_detect(url_data, "subject_fixed")] #TRUE와 FALSE로 나타나는 결과값을 배열에 넣으면 TRUE인 원소만 출력된다
# 2. 추출한 데이터 전체에서 내가 필요한 문자열만 추출
# str_extract -> 패턴에 일치하는 문자열을 리턴
# 후방, 전방 탐색 정규 표현식
str_extract(filter_data, "(?<=\">).*(?=</span>)")
filter_data
title
# 2. 추출한 데이터 전체에서 내가 필요한 문자열만 추출
# str_extract -> 패턴에 일치하는 문자열을 리턴
# 후방, 전방 탐색 정규 표현식
title <- str_extract(filter_data, "(?<=\">).*(?=</span>)")
title
#### 데이터 필터링: hit ####
# 패턴: 큰따옴표는 앞에 \를 붙이면 문자로 인식한다.
# (자바스크립트는 작은따옴표)
hit_data <- url_data[str_detect(url_data, "<span class=\"hit\">")]
hit_data
hit <- str_extract(hit_data, "(?<=\">).*(?=</span>)")
hit
#### 데이터 필터링: url ####
which(str_detect(url_data, "subject_fixed"))
#### 데이터 필터링: url ####
str_detect(url_data, "subject_fixed")
which(str_detect(url_data, "subject_fixed"))
which(str_detect(url_data, "subject_fixed")-2) #TRUE인 위치값을 뽑아낸다
(which(str_detect(url_data, "subject_fixed"))-2) #TRUE인 위치값을 뽑아낸다
#### 데이터 필터링: url ####
str_detect(url_data, "subject_fixed")
#TRUE인 위치값에서 세 번 위로(중간에 공백 있음) 올라간 값을 뽑아낸다 = url위치
myurl <- url_data[which(str_detect(url_data, "subject_fixed"))-3]
myurl
url_val <- str_extract(hit_data, "(?<=href=\").*(?=data-role)")
url_val
url_val <- str_extract(myurl, "(?<=href=\").*(?=data-role)")
url_val
url_val <- str_extract(myurl, "(?<=href=\").*(?=\" \"data-role)")
url_val
url_val <- str_extract(myurl, "(?<=href=\").*(?= \"data-role)")
url_val
url_val <- str_extract(myurl, "(?<=href=\").*(?=data-role)")
url_val
url_val
url_val <- paste0("https://www.clien.net",url_val)
url_val
# 필요 없는 문자열을 잘라내기, end: 끝에서부터 자른다
url_val <- str_sub(url_val, end=3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
# 필요 없는 문자열을 잘라내기, end: 뒤에서 3개를 잘라내기
url_val <- str_sub(url_val, end= -3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
str_detect(url_data, "subject_fixed")
#TRUE인 위치값에서 세 번 위로(중간에 공백 있음) 올라간 값을 뽑아낸다 = url위치
myurl <- url_data[which(str_detect(url_data, "subject_fixed"))-3]
myurl
url_val <- str_extract(myurl, "(?<=href=\").*(?=data-role)")
# 필요 없는 문자열을 잘라내기, end: 뒤에서 3개를 잘라내기
url_val <- str_sub(url_val, end= -3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
#### csv파일로 생성 ####
final_data <- cbind(title, hit, url_val)
final_data
write.csv("crawl_data.csv")
write.csv(final_data, file= "crawl_data.csv")
install.packages("mongolite")
library("mongolite")
library("stringr")
url <- "https://www.clien.net/service/group/community?&od=T31&po=0"
url_data <- readLines(url, encoding = "UTF-8") # url접속도 대신해줌(사이트에서 정보 받아옴)
# 인코딩 확인!!
url_data
# 정보확인=============================
#class(url_data) #character
#length(url_data)
#head(url_data)
#tail(url_data)
# =====================================
url_data[200]
# 조건에 만족하는 데이터를 필터링
# 문자열에 패턴을 적용해서 일치여부를 T/F로 리턴
#### 데이터 필터링: title ####
# 1. str_detect(패턴을 검사할 문자열, 패턴)를 이용해서 웹페이지 전체에서 필요한 데이터만 먼저 추출 -> TRUE와 FALSE를 리턴
# 클래스명으로 뽑기
filter_data <- url_data[str_detect(url_data, "subject_fixed")] #TRUE와 FALSE로 나타나는 결과값을 배열에 넣으면 TRUE인 원소만 출력된다
filter_data
# 2. 추출한 데이터 전체에서 내가 필요한 문자열만 추출
# str_extract -> 패턴에 일치하는 문자열을 리턴
# 후방, 전방 탐색 정규 표현식
title <- str_extract(filter_data, "(?<=\">).*(?=</span>)")
title
#### 데이터 필터링: hit(조회수) ####
# 패턴: 큰따옴표는 앞에 \를 붙이면 문자로 인식한다.
# (자바스크립트는 작은따옴표)
# 태그로 뽑기
hit_data <- url_data[str_detect(url_data, "<span class=\"hit\">")]
hit_data
hit <- str_extract(hit_data, "(?<=\">).*(?=</span>)")
hit
#### 데이터 필터링: url ####
str_detect(url_data, "subject_fixed")
#TRUE인 위치값에서 세 번 위로(중간에 공백 있음) 올라간 값을 뽑아낸다 = url위치
myurl <- url_data[which(str_detect(url_data, "subject_fixed"))-3]
myurl
url_val <- str_extract(myurl, "(?<=href=\").*(?=data-role)")
# 필요 없는 문자열을 잘라내기, end= -3 뒤에서 3개를 잘라내기
url_val <- str_sub(url_val, end= -3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
# =>링크를 타고 타고 들어가서 크롤링 하는 상황에서 사용
#### csv파일로 생성 ####
final_data <- cbind(title, hit, url_val)
final_data
write.csv(final_data, file= "crawl_data.csv")
install.packages("mongolite")
library("mongolite")
library("stringr")
url <- "https://www.clien.net/service/group/community?&od=T31&po=0"
url_data <- readLines(url, encoding = "UTF-8") # url접속도 대신해줌(사이트에서 정보 받아옴)
# 인코딩 확인!!
url_data
# 정보확인=============================
#class(url_data) #character
#length(url_data)
#head(url_data)
#tail(url_data)
# =====================================
url_data[200]
# 조건에 만족하는 데이터를 필터링
# 문자열에 패턴을 적용해서 일치여부를 T/F로 리턴
#### 데이터 필터링: title ####
# 1. str_detect(패턴을 검사할 문자열, 패턴)를 이용해서 웹페이지 전체에서 필요한 데이터만 먼저 추출 -> TRUE와 FALSE를 리턴
# 클래스명으로 뽑기
filter_data <- url_data[str_detect(url_data, "subject_fixed")] #TRUE와 FALSE로 나타나는 결과값을 배열에 넣으면 TRUE인 원소만 출력된다
filter_data
# 2. 추출한 데이터 전체에서 내가 필요한 문자열만 추출
# str_extract -> 패턴에 일치하는 문자열을 리턴
# 후방, 전방 탐색 정규 표현식
title <- str_extract(filter_data, "(?<=\">).*(?=</span>)")
title
#### 데이터 필터링: hit(조회수) ####
# 패턴: 큰따옴표는 앞에 \를 붙이면 문자로 인식한다.
# (자바스크립트는 작은따옴표)
# 태그로 뽑기
hit_data <- url_data[str_detect(url_data, "<span class=\"hit\">")]
hit_data
hit <- str_extract(hit_data, "(?<=\">).*(?=</span>)")
hit
#### 데이터 필터링: url ####
str_detect(url_data, "subject_fixed")
#TRUE인 위치값에서 세 번 위로(중간에 공백 있음) 올라간 값을 뽑아낸다 = url위치
myurl <- url_data[which(str_detect(url_data, "subject_fixed"))-3]
myurl
url_val <- str_extract(myurl, "(?<=href=\").*(?=data-role)")
# 필요 없는 문자열을 잘라내기, end= -3 뒤에서 3개를 잘라내기
url_val <- str_sub(url_val, end= -3)
url_val <- paste0("https://www.clien.net",url_val)
url_val
# =>링크를 타고 타고 들어가서 크롤링 하는 상황에서 사용
#### csv파일로 생성 ####
final_data <- cbind(title, hit, url_val)
final_data
write.csv(final_data, file= "crawl_data.csv")
length(title)
length(git)
length(url_val)
length(hit)
