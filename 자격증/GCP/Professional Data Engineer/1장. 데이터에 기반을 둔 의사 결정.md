# 1장. 데이터에 기반을 둔 의사 결정

데이터 분석의 주요 목적은 **의사 결정을 돕는 것**이다.

- 데이터를 수집하면 종종 수집 인프라 및 해당 인프라의 보안에 대한 요구사항이 필요하다.
- 여러 당사자가 관여할 때마다 데이터의 `감사 가능성`은 중요하며, 데이터의 소유권과 사용은 별개이다.
  - 데이터가 **검증**되지 않았을 때 시장에서 실패하게 되고, 최적의 의사 결정을 내릴 수 없으며, 관련 당사자는 시장의 시그널과 모니터링에만 의존해야 한다.
- 데이터 분석을 시작하기 위한 **목적**은 반드시 결정해야 할 사항이다.
  - 이제는 관련 데이터가 어디에나 있기 때문에 더 이상 경험적인 규칙에 기반을 두고 결정을 내릴 필요가 없다. 이제는 데이터 기반으로 의사 결정을 할 수 있다.

## 많은 유사한 의사 결정

센서와 저장소에 관련된 비용이 낮아졌기 때문에 데이터 기반 의사결정을 지원하는 더 많은 산업과 사례가 등장할 것이다.

> **궁극적인 목표는 (반복 가능하고 확장 가능한)의사 결정 기능을 고객에게 서비스로 제공하는 것이다.**

통찰력을 얻기 위해 다음과 같은 기법들을 적용할 수 있다.

- 다양한 통계
- 머신 러닝 방법

단순히 데이터를 수집하거나 그대로 사용하는 것만으로는 충분하지 않다. 데이터를 **이해**해야 한다.

[서비스에 대한 품질 평가]

- 의사 결정 자체의 품질
  - 얼마나 정확한가?
  - 오류의 원인은 무엇인가?
  - 이 시스템을 어떠한 상황에 사용하지 말아야 하는가?
- 서비스의 품질
  - 얼마나 신뢰할 수 있는가?
  - 초당 몇 개의 쿼리를 제공할 수 있는가?
  - 사용 가능한 일부 데이터와 체계적인 의사 결정을 제공하는 데 사용하는 모델을 통합하는 데 걸리는 시간은 얼마나 되는가?



## 데이터 엔지니어의 역할

개인적으로나 전문적으로 고려해야 할 모든 요소들은 다음과 같다.

- 데이터 분석은 의사 결정을 지원한다.
- 데이터에 기반을 둔 의사 결정은 경험에 의한 방법보다 월등할 수 있다.
- 의사 결정 모델의 정확성은 적절한 통계나 머신 러닝 방법의 선택에 좌우된다.
- 데이터에 있는 뉘앙스(미묘한 차이)가 모델링을 완전히 무시할 수 있으므로 데이터와 데이터의 결점을 이해하는 것은 필수적이다.
- 의사 결정을 체계적으로 지원하고 이를 서비스로 제공하는 큰 시장의 기회가 있다.
- 이런 서비스는 **지속적인 데이터 수집 및 모델 업데이트**가 요구된다.
- 지속적인 데이터 수집에는 **강력한 보안 및 감사**가 포함된다.
- 서비스를 사용하는 고객은 안정성, 정확성 및 응답 시간에 대한 보장을 요구한다.

> 데이터 엔지니어를 "데이터 분석을 수행해 비즈니스 산출물을 생성할 수 있는" 모든 사람에 대한 포괄적인 용어로 간주할 수 있을 것이다.

구글이 인정하는 데이터 엔지니어의 역량은 다음과 같다.

- 계산중인 특정 집계가 의미가 있도록 만드는 통계적인 설정 (`통계 구축`)

- 목표로 하고 있는 비즈니스 결과를 이끌어낼 수 있는 분석 방법에 대한 이해 (`머신 러닝 모델 구축`)
  - 특정한 비즈니스 문제를 해결하기 위해 통계적으로 유효한 데이터 분석을 수행하는 능력은 매우 중요하다. 

    쿼리, 보고서, 그래프는 최종 목표가 아니다. **검증 가능한 정확한 결정**이 최종 목표다.

- 그리고 위에서 구축한 모델을 `자동화`할 수 있어야 한다.
  - **데이터 분석은 확장이 필요하다**. 

    의사 결정 프로세스는 반복적이어야 하고, 혼자가 아니라 여러 사람에 의해 수행될 수 있어야 한다.

    데이터 엔지니어가 알고리즘을 고안한 후 그 알고리즘을 체계적이고 반복적으로 사용할 수 있어야 한다.

  - 안정성, 신뢰성, 내결함성, 확장성 및 효율성을 갖춘 데이터 처리 시스템을 설계·구축해야 한다.

즉, 데이터 과학을 알고 있는 엔지니어를 말한다.



현재로서는 빅데이터 분야에서 데이터 엔지니어가 가장 수요가 많은 직업이다.

- 데이터베이스 스키마를 설계할 수 있고 SQL 쿼리를 작성할 수 있으며,
- 머신 러닝 모델을 훈련시킬 수 있고,
- 데이터 처리 파이프라인을 코딩할 수 있고 어떻게 확장할 수 있는지 그림을 그릴 수 있는

누군가를 찾을 가능성이 얼마나 되는가?

그러나 이러한 일을 하기 위해 필요한 지식의 양이 몇 년 전보다 훨씬 적어졌기 때문에 가능하다.



## 클라우드는 데이터 엔지니어를 능력자로 만든다

클라우드로의 지속적인 이동 때문에 데이터 엔지니어는 **네 가지 다른 분야**의 기술 작업을 수행할 수 있다.

[클라우드의 특징]

- 자동 확장
- 서버리스(= 자동 확장 및 완벽히 관리되는 서비스)
- 관리가 용이한 관리형 인프라

단순히 온프레미스 인프라에 돌고 있는 워크로드를 퍼블릭 클라우드 공급업체가 제공하는 인프라로 이전하는 것만을 의미하는 것이 아니다.

대신 수많은 인프라 프로비저닝, 모니터링 및 관리를 자동화하는 진정한 자동 확장 및 관리 서비스를 의미하는 것이다.

- 구글 클라우드 플랫폼상의 구글 빅쿼리(BigQuery), 클라우드 데이터플로우 및 클라우드 머신 러닝 엔진과 같은 서비스들



데이터 과학 자체는 덜 복잡해지고 덜 난해해지고 있다.

잘 설계된 패키지와 사용하기 쉬운 API를 사용함으로써 모든 데이터 과학 알고리즘을 직접 구현할 필요가 없다.

- 알아야 할 것은 각 알고리즘이 하는 일을 아는 것과 현실적인 문제를 해결하기 위해 해당 알고리즘을 연결시키는 일뿐이다.

데이터 과학 도구들도 사용하기가 점점 더 간단해지고 있다.

- 스파크(Spark)
- 사이킷-런(scikit-learn)
- 판다스(Pandas)

요즘의 **데이터 분석가**와 **데이터베이스 관리자**는 완전히 다른 백그라운드와 스킬셋을 가진다.

- 데이터 분석은 보통 심도 있는 SQL 처리 능력을 포함하고
- 데이터베이스 관리는 데이터베이스 색인과 튜닝에 대한 깊은 지식을 포함한다.
  - `빅쿼리(BigQuery)`와 같은 도구의 도입으로 테이블이 **비정규화**되고 관리 오버 헤드는 최소화돼 데이터베이스 관리자의 역할은 상당 부분 감소됐다.
  - 기업 내에 있는 모든 데이터 저장소와 연결되는 `타블루(Tableau)`와 같은 턴키 시각화 도구의 가용성이 증가함으로써 더 넓은 범위의 사람들이 상호작용할 수 있게 되었다.

구글에서는 누군가에게 질문을 하면 실제 답변이 아닌 빅쿼리 뷰 또는 쿼리에 대한 링크를 제공받을 가능성이 높다.

- "가장 최근의 답변이 알고 싶을 때마다 이 쿼리를 실행하세요." 
- 빅쿼리는 관리형 데이터베이스에서 **셀프 서비스 데이터 분석 솔루션**으로 탈바꿈했다.



## 클라우드는 데이터 과학을 급속도로 변화시킨다

온프레미스 환경에서 처리하던 것보다 10배 많은 시스템에서 작업을 수행하는 비용이 훨씬 더 많이 들까?

- 아니다. 처리 능력을 구매하는 것보다 처리 시간을 임대하는 것이 더 경제적이기 때문이다.
- 10대의 장비를 투입해 10시간 처리하는 것이나 100대의 장비를 투입해 1시간 처리하는 것이나 **비용은 동일하다**. 그러므로 1시간 안에 정답을 얻는 것을 선택하는 것이 합리적이다.

또, 자동으로 확장되는 수천 대의 시스템에 데이터를 처리하고 분석하고 머신 러닝을 하는 것은 확실한 이점이다.

- 테라바이트 수준의 데이터를 조회하는 데 어떠한 인프라도 관리하지 않는다면 이는 커다란 이점이다.
- `클라우드 데이터플로우`와 같은 자동 확장형 데이터 처리 파이프라인을 사용한다.

클라우드에서 데이터 엔지니어링을 수행할 때 얻는 **주요 이점은 시간을 절약할 수 있다는 점**이다.

- 며칠이나 몇 년을 기다릴 필요 없이, 많은 작업을 **병렬**로 진행하여 수천 대의 시스템에서 처리하면 몇 분에서 몇 시간 만에 결과를 얻을 수 있다.



한 번에 수천 대의 시스템에서 몇 분 동안 데이터 작업을 실행하려면 `완전하게 관리되는 서비스`가 필요하다.

[고효율 네트워크를 이용하는 `자동 확장 서비스`의 필요성]

- 컴퓨터 노드 또는 HDFS(하둡 분산 파일 시스템) 같은 영구 디스크에 자료를 로컬하게 저장하면, 어떤 작업이 언제 어디에서 실행이 되는지 정확히 알지 못한다면 확장시킬 수 없다.
- 따라서 **클러스터의 노드 간 작업의 동적인 이동**이 가능하고, 동적으로 클러스터 크기를 조정하고, 노드 간의 데이터를 이동시키기 위해 `고효율 네트워크`가 필요하다.
  - 구글 플랫폼에서 제공하는 자동 확장 서비스
    - 빅 쿼리 (SQL 분석)
    - 클라우드 데이터플로우 (데이터 처리 파이프라인)
    - 구글 클라우드 pub/sub (메시지 기반 시스템)
    - 구글 클라우드 빅테이블 (대량 입수)
    - 구글 앱 엔진 (웹 애플리케이션)
    - 클라우드 머신 러닝 엔진 (머신 러닝)
  - 비즈니스의 실제적으로 중요한 문제를 해결하는데 좀 더 많은 시간을 할애할 수 있도록 **서버리스 제품을 선택하라**.



## 사례 연구로 확고한 사실을 얻을 수 있다

사례 연구는 토론을 계속할 수 있게 도와준다.

불행하게도 데이터 분석 및 머신 러닝 분야의 사례 연구는 매우 희귀하다.

- 책들과 교과서는 현실성이 떨어지는 문제에 대한 잘 정돈된 가벼운 솔루션들로 가득 차 있다.
- 특정한 접근법의 기초가 되는 직관에 대해서 알아볼 필요가 있다.

현실세계의 사례 연구

1. 현실적인 문제 해결을 위해 현실 세계의 데이터셋을 사용하고, 거기에서 발생하는 문제를 다룬다.
2. 데이터 기반 결정을 내리는 통찰력을 얻기 위해, 여러 가지 통계 및 머신 러닝 방법을 적용해야 하는 의사 결정 문제에서 시작한다.
3. 간단한 솔루션으로 시작해 더 복잡한 솔루션으로 나아간다.
   - 복잡한 솔루션에서 시작하면 더 간단한 방법으로 해결할 때 더 잘 이해할 수 있을 **문제의 세부 내용이 모호해질 수 있다**.
4. 초기에 시도한 솔루션(모델)은 기록·유지해두고, 진행 과정에서 배운 내용으로 초기 모델을 지속적으로 강화하기를 강력하게 추천한다. (`평행 실험`)
   - 적극적으로 **여러 가지 모델을 지속적으로 관리**하기를 추천한다.
   - 유사한 정확도를 갖는 두 모델에 대한 선택지가 주어진다면, **더 단순한 모델을 선택**할 수 있다.
     - 더 단순한 접근 방법에 약간의 변경을 통해 작업할 수 있으므로 더 복잡한 모델을 사용하는 것은 비상식적이다.



## 확률론적 결정

비행기가 늦게 출발한다는 사실에 대해 여러 출장자들이 회의를 취소해야 할지 말지 고민한다.

여행자의 일정을 조회해 지각할 수도 있는 일정이 있는 경우 회사의 서버에서 여행자에게 예상 지연에 대해 경고 메시지를 발송할 수 있다면 아주 좋을 것이다.

이를 처리할 수 있는 데이터 프레임워크를 구축해보자.

> **확률론적 접근법**은 데이터 기반 의사결정 방법 중 하나이다.

- 회의를 놓친 것에 따른 확률과 금전적인 손실을 알면, 모든 결정에 대한 기대치를 계산할 수 있기 때문에 확률론적 접근이 더 일반적이 될 수 있다.

