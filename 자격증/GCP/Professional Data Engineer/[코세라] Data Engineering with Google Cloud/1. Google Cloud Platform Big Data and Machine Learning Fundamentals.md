# 1. Google Cloud Platform Big Data and Machine Learning Fundamentals

> - Recall the four big data challenges you will learn how to solve
> - Understand the Qwiklabs interactive lab environment that you will be using
> - Identify the critical data roles in an organization
> - Analyze large datasets with BigQuery in your lab

## 1) Introduction to Google Cloud Platform

four big data challenges

1. Migrating existing data workloads (ex: Hadoop, Spark jobs)

   : effectively analyze all of your data.

2. Analyzing large datasets at scale

   : TB ~ PB scale

3. Building streaming data pipelines

   : to make data-driven decisions more quickly.

4. Applying machine learning to your data

   : able to make predictive forward-looking actions.

### Introduction to Google Cloud Platform

원래는 구글 어플리케이션에 적용하던 인프라를 이제 일반에게도 제공한다.

#### Compute

: 미래에 유저와 데이터의 증가를 지원하기 위해 많은 compute power가 필요하다.

- 특히 머신 러닝에서는 상당한 compute resources가 필요하다.

  - Automatic Video Stabilization for Google Photos
    : 비디오의 이미지 스틸샷(정적인 순간), 폰 자이로스코프, 렌즈 모션 데이터

  -  TPUs (Tensor Processing Units)

    : ML에 특화된 하드웨어. 구글 클라우드를 통해서 다른 비즈니에서도 사용할 수 있다.

  - 구글 데이터센터의 쿨링 비용을 감소시키는데 ML 사용

**[Demo: Creating a VM on Compute Engine]**

> USGS의 earthquake 데이터 사용

1. compute engine instance 작동시키기

   : 메뉴의 [Compute Engine] 항목 -> [VM instances]

   [Create] -> [New VM instance] 

   - 인스턴스 이름: 마음대로
   - 리전: asia-northeast3(서울)
   - 영역: asia-northeast3-a
   - 머신 유형: e2-medium(vCPU 2개, 4GB 메모리)
   - 부팅 디스크: Debian GNU/Linux 10, 표준 영구 디스크 10GB
   - ID 및 API 액세스 > 액세스 범위: 모든 Cloud API에 대한 전체 액세스 허용
     - VM에서 Cloud Storage에 write 할 수 있다.
   - 방화벽: 기본값
     - HTTP/HTTPS 트래픽 허용은 나중에. 지금은 SSH로만 접근할 수 있도록 설정한다.

2. 그 위에서 소프트웨어 실행하기

   : VM instance의 이름을 클릭하면 ssh로 virtual machine에 접속할 수 있다.

   - git 설치하기

     - `sudo`로 root 권한에 access 할 수 있다.

       ``` bash
       ~$ sudo apt-get install git
       ~$ git clone https://www.github.com/GoogleCloudPlatform/training-data-analyst
       ```

   - bdml_fundamental 폴더로 가서 earthquakevm 폴더로 간다.

     - `ingest.sh` - data를 ingest하는 셸 스크립트 파일. wget 명령어로 URL에서 earthquakes.csv 파일을 다운로드 한다.

       `transform.py` - matplotlib을 이용해 data를 parse해서 Earth map에 뿌려 PNG파일을 생성한다.

       `install_missing.sh` - 필요한 파이썬 패키지를 설치한다.

       ``` bash
       $ ./install_missing.sh
       $ ./ingest.sh # csv파일 다운로드(earthquakes.csv)
       $ ./transform.py # PNG파일 생성(earthquakes.png)
       ```

3. compute engine instance에서 cloud storage로 파일 복사하기

   : **Compute와 Storage는 분리되어 있으므로 작업이 끝난 후, 완료된 작업물을 Cloud Storage에 올리고 VM은 삭제하는 것을 목표로 한다.**

   메뉴의 [Storage] 항목 -> [Browser]

   [Create a bucket] 

   - bucket name은 globally unique 해야한다.
     - project name도 globally unique하기 때문에 프로젝트 네임을 그대로 사용해도 된다.
   - Multi-Regional - 세계 어디에서든 접속할 수 있다.
   - Set object-level and bucket-level permissions 체크

   `gsutil` 명령어를 통해 조작할 수 있다.

   ``` bash
   $ gsutil ls gs://<버킷이름>
   $ gsutil cp earthquakes.* gs://<버킷이름>
   ```

4. 그 파일들을 public에 publish하기

   : [REFRESH BUCKET]을 눌러 3개의 파일이 저장된 것을 확인하고, VM을 Stop하거나 Delete을 한다.

   VM 위에서 다른 소프트웨어를 돌릴 예정이지만, 작업이 종료된 후이므로 payment를 지불하기 싫다면 Stop을 하면 된다.

   파일들은 **Not public**으로 설정되어 있다. (파일 소유자만 접근 가능) 

   - 모두가 접근할 수 있도록 public으로 설정하기
     - 원하는 파일을 체크한 뒤 [Permissions] 탭으로 간다.
     - Add members 클릭
       - New members - allUsers 선택
       - Role - Storage Object Viewer
     - 링크를 통해 모두가 볼 수 있다.

   > **결론**: VM이 없어도 파일을 서비스할 수 있다.

#### Storage

: Storage는 Compute instance와 분리되어야 한다. (Compute and storage are independent)

그래야 우리가 데이터를 분석, 변환, 모델에 입력할 수 있다.

=> 이것이 클라우드 컴퓨팅과 데스크탑 컴퓨팅의 major한 차이이다.

- 데이터 엔지니어는 pipeline이 완성된 후, 데이터를 복제(replicate)하고, 백업하고, 스케일하고, 삭제해야 한다.
- 웹UI(`console.cloud.google.com`)를 사용하거나 CLI에서 `gsutil(Google Storage Utility)` 함수를 사용하여 Storage bucket을 제어할 수 있다.

**[storage classes]**

![](images/1_storage_option.JPG)

- 모든 클래스는 multi-region, dual-region 등 region location options를 지원한다.

- access speed와 cost에 따라 다르다.

- Standard Storage가 가장 빠르고, Archive Storage가 가장 저렴하다.

  Nearline Storage는 한 달에 한 번 정도 접근하는 데이터를 저장하기에 적합하다.

- 보통 데이터 분석을 위해서는 데이터를 staging하려는 region 내에서 Standard Storage를 이용하는 옵션을 선택한다. (within a region)

  - 컴퓨팅과 저장소를 한 장소(single region)에 Co-locating함으로서 네트워크 비용을 줄이고 효율을 극대화할 수 있다.

**[Google Cloud Platform resource hierarchy]**

#### Networking



#### Security

